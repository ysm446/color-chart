# Color Chart

ç¾è¡“ç†è«–ã«åŸºã¥ã„ãŸç”»åƒåˆ†æãƒ„ãƒ¼ãƒ«ã€‚ãƒ­ãƒ¼ã‚«ãƒ«Vision LLMï¼ˆQwen3-VLï¼‰ã‚’ä½¿ç”¨ã—ã¦ã€ç”»åƒã®ã‚«ãƒ©ãƒ¼ã‚¹ã‚­ãƒ¼ãƒ ã€ã‚³ãƒ³ãƒã‚¸ã‚·ãƒ§ãƒ³ã€å½©åº¦åˆ†å¸ƒãªã©ã‚’å°‚é–€çš„ã«åˆ†æã—ã¾ã™ã€‚

## æ©Ÿèƒ½

### ã‚«ãƒ©ãƒ¼åˆ†æ
- æ”¯é…çš„ãªè‰²ã®æŠ½å‡ºï¼ˆK-means clusteringï¼‰
- ã‚«ãƒ©ãƒ¼ã‚¹ã‚­ãƒ¼ãƒ åˆ†é¡
  - Complementaryï¼ˆè£œè‰²ï¼‰
  - Split-Complementaryï¼ˆåˆ†è£‚è£œè‰²ï¼‰
  - Analogousï¼ˆé¡ä¼¼è‰²ï¼‰
  - Triadicï¼ˆä¸‰è§’é…è‰²ï¼‰
  - Monochromaticï¼ˆå˜è‰²ï¼‰
- è‰²æ¸©åº¦åˆ†æï¼ˆæš–è‰²vså¯’è‰²ã®æ¯”ç‡ï¼‰
- RGB/HEXå€¤ã®è¡¨ç¤ºã¨å‰²åˆ

### ã‚³ãƒ³ãƒã‚¸ã‚·ãƒ§ãƒ³åˆ†æ
- ãƒ•ã‚©ãƒ¼ã‚«ãƒ«ãƒã‚¤ãƒ³ãƒˆæ¤œå‡ºï¼ˆç›¸å¯¾åº§æ¨™ï¼‰
- ãƒã‚¬ãƒ†ã‚£ãƒ–ã‚¹ãƒšãƒ¼ã‚¹ã®è©•ä¾¡
- è¦–ç·šã®æµã‚Œåˆ†æ
- æ§‹å›³ã‚¿ã‚¤ãƒ—ã®åˆ¤å®šï¼ˆä¸‰åˆ†å‰²æ³•ã€é»„é‡‘æ¯”ãªã©ï¼‰
- ãƒãƒ©ãƒ³ã‚¹è©•ä¾¡ï¼ˆå¯¾ç§°/éå¯¾ç§°ï¼‰
- å¼·ã¿ã¨æ”¹å–„ææ¡ˆ

### ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ©ã‚¤ã‚¼ãƒ¼ã‚·ãƒ§ãƒ³
- ä¸‰åˆ†å‰²æ³•ã‚°ãƒªãƒƒãƒ‰ã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤
- ãƒ•ã‚©ãƒ¼ã‚«ãƒ«ãƒã‚¤ãƒ³ãƒˆè¡¨ç¤º
- å½©åº¦ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—
- è¤‡åˆè¡¨ç¤ºãƒ¢ãƒ¼ãƒ‰

### ãƒ¢ãƒ‡ãƒ«ç®¡ç†
- ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ä¸€è¦§è¡¨ç¤º
- ãƒ¢ãƒ‡ãƒ«ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰é€²æ—è¡¨ç¤º
- ãƒ­ãƒ¼ã‚«ãƒ«ã«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®ç®¡ç†
- ãƒ¢ãƒ‡ãƒ«ã®å‰Šé™¤æ©Ÿèƒ½
- ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ä½¿ç”¨é‡ã®è¡¨ç¤º

## æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯

- **UI**: Gradioï¼ˆãƒ‰ãƒ©ãƒƒã‚°&ãƒ‰ãƒ­ãƒƒãƒ—å¯¾å¿œã€ã‚¿ãƒ–ãƒ™ãƒ¼ã‚¹UIï¼‰
- **Vision LLM**: Qwen3-VL-4B/8B (TransformersçµŒç”±)
- **ç”»åƒå‡¦ç†**: Pillow, OpenCV
- **ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°**: scikit-learn (K-means)
- **Python**: 3.10+

## ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—

### å¿…è¦è¦ä»¶

- Python 3.10ä»¥ä¸Š
- VRAM 8GBä»¥ä¸Šï¼ˆ4Bãƒ¢ãƒ‡ãƒ«ï¼‰/ 16GBä»¥ä¸Šï¼ˆ8Bãƒ¢ãƒ‡ãƒ«æ¨å¥¨ï¼‰
- CUDAå¯¾å¿œGPUï¼ˆæ¨å¥¨ã€CPUã§ã‚‚å‹•ä½œå¯èƒ½ã ãŒéå¸¸ã«é…ã„ï¼‰
- ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸: 20GBä»¥ä¸Šï¼ˆãƒ¢ãƒ‡ãƒ«ä¿å­˜ç”¨ï¼‰

### ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ‰‹é †

1. **ãƒªãƒã‚¸ãƒˆãƒªã®ã‚¯ãƒ­ãƒ¼ãƒ³**
```bash
git clone <repository-url>
cd color-chart
```

2. **Pythonãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«**
```bash
# ä»®æƒ³ç’°å¢ƒã®ä½œæˆï¼ˆæ¨å¥¨ï¼‰
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# åŸºæœ¬ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu121  # CUDA 12.1ç‰ˆ
# ã¾ãŸã¯ CPUç‰ˆ: pip install torch torchvision

# å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒª
pip install -r requirements.txt
```

3. **ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®èµ·å‹•**
```bash
python color_chart.py
```

åˆå›èµ·å‹•æ™‚ã¯è‡ªå‹•çš„ã«ãƒ¢ãƒ‡ãƒ«ç®¡ç†ãƒšãƒ¼ã‚¸ãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚

4. **ãƒ¢ãƒ‡ãƒ«ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰**
- ãƒ–ãƒ©ã‚¦ã‚¶ã§ `http://localhost:7860` ã«ã‚¢ã‚¯ã‚»ã‚¹
- ã€ŒğŸ”§ ãƒ¢ãƒ‡ãƒ«ç®¡ç†ã€ã‚¿ãƒ–ã‚’é–‹ã
- ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ãƒªã‚¹ãƒˆã‹ã‚‰é¸æŠ
- ã€Œãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã€ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯
- ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Œäº†å¾Œã€ã€ŒğŸ¨ åˆ†æã€ã‚¿ãƒ–ã§ä½¿ç”¨å¯èƒ½

## ä½¿ã„æ–¹

### ãƒ¢ãƒ‡ãƒ«ç®¡ç†
1. **åˆå›ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—**: ã€ŒğŸ”§ ãƒ¢ãƒ‡ãƒ«ç®¡ç†ã€ã‚¿ãƒ–ã§ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
2. **ãƒ¢ãƒ‡ãƒ«ç¢ºèª**: ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ãƒªã‚¹ãƒˆã§çŠ¶æ…‹ç¢ºèª
3. **ãƒ¢ãƒ‡ãƒ«å‰Šé™¤**: ä¸è¦ãªãƒ¢ãƒ‡ãƒ«ã‚’å‰Šé™¤ã—ã¦ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã‚’ç¯€ç´„

### ç”»åƒåˆ†æ
1. **ç”»åƒã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰**: ãƒ‰ãƒ©ãƒƒã‚°&ãƒ‰ãƒ­ãƒƒãƒ—ã¾ãŸã¯ã‚¯ãƒªãƒƒã‚¯ã—ã¦ç”»åƒã‚’é¸æŠ
2. **ãƒ¢ãƒ‡ãƒ«é¸æŠ**: ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‹ã‚‰é¸æŠ
3. **åˆ†æé …ç›®ã®é¸æŠ**: ã‚«ãƒ©ãƒ¼åˆ†æã€ã‚³ãƒ³ãƒã‚¸ã‚·ãƒ§ãƒ³åˆ†æãªã©ã‚’ãƒã‚§ãƒƒã‚¯
4. **åˆ†æå®Ÿè¡Œ**: ã€ŒğŸ” åˆ†æé–‹å§‹ã€ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯
5. **ã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤è¡¨ç¤º**: å¿…è¦ã«å¿œã˜ã¦ã‚°ãƒªãƒƒãƒ‰ã‚„ãƒ•ã‚©ãƒ¼ã‚«ãƒ«ãƒã‚¤ãƒ³ãƒˆã‚’è¡¨ç¤º
6. **çµæœã®ç¢ºèª**: ã‚«ãƒ©ãƒ¼ã‚¹ã‚¦ã‚©ãƒƒãƒã¨ã‚³ãƒ³ãƒã‚¸ã‚·ãƒ§ãƒ³è©³ç´°ã‚’ç¢ºèª

## ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹æˆ
```
color-chart/
â”œâ”€â”€ color_chart.py          # ãƒ¡ã‚¤ãƒ³ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³
â”œâ”€â”€ model_manager.py        # ãƒ¢ãƒ‡ãƒ«ç®¡ç†ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
â”œâ”€â”€ CLAUDE.md               # ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆä»•æ§˜æ›¸ï¼‰
â”œâ”€â”€ requirements.txt        # Pythonä¾å­˜é–¢ä¿‚
â”œâ”€â”€ .gitignore              # Gité™¤å¤–è¨­å®š
â”œâ”€â”€ config.json             # ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³è¨­å®šï¼ˆè‡ªå‹•ç”Ÿæˆï¼‰
â””â”€â”€ models/                 # ãƒ­ãƒ¼ã‚«ãƒ«ãƒ¢ãƒ‡ãƒ«ä¿å­˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
    â”œâ”€â”€ Qwen3-VL-4B-Instruct/
    â””â”€â”€ Qwen3-VL-8B-Instruct/
```

## ãƒ¢ãƒ‡ãƒ«ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ 

### å¯¾å¿œãƒ¢ãƒ‡ãƒ«ä¸€è¦§

ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã¯ä»¥ä¸‹ã®ãƒ¢ãƒ‡ãƒ«ã«å¯¾å¿œã—ã¦ã„ã¾ã™ï¼š

| ãƒ¢ãƒ‡ãƒ«å | ã‚µã‚¤ã‚º | VRAM | é€Ÿåº¦ | ç²¾åº¦ | æ¨å¥¨ç”¨é€” |
|---------|--------|------|------|------|----------|
| Qwen3-VL-4B-Instruct | ~8GB | 8-10GB | é«˜é€Ÿ | è‰¯å¥½ | ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—/ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ  |
| Qwen3-VL-8B-Instruct | ~16GB | 14-18GB | ä¸­é€Ÿ | å„ªç§€ | æœ¬ç•ªä½¿ç”¨/è©³ç´°åˆ†æ |

### ãƒ¢ãƒ‡ãƒ«ç®¡ç†ãƒšãƒ¼ã‚¸ã®æ©Ÿèƒ½

1. **ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¯èƒ½ãƒ¢ãƒ‡ãƒ«**
   - Hugging Faceã§å…¬é–‹ã•ã‚Œã¦ã„ã‚‹ãƒ¢ãƒ‡ãƒ«ã®ãƒªã‚¹ãƒˆ
   - ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºã€VRAMè¦ä»¶ã®è¡¨ç¤º
   - ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³

2. **ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«**
   - ãƒ­ãƒ¼ã‚«ãƒ«ã«ä¿å­˜ã•ã‚Œã¦ã„ã‚‹ãƒ¢ãƒ‡ãƒ«ã®ãƒªã‚¹ãƒˆ
   - ãƒ‡ã‚£ã‚¹ã‚¯ä½¿ç”¨é‡ã®è¡¨ç¤º
   - æœ€çµ‚ä½¿ç”¨æ—¥æ™‚
   - å‰Šé™¤ãƒœã‚¿ãƒ³

3. **ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰é€²æ—**
   - ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã®é€²æ—ãƒãƒ¼
   - ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰é€Ÿåº¦
   - æ¨å®šæ®‹ã‚Šæ™‚é–“

4. **ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸æƒ…å ±**
   - åˆè¨ˆä½¿ç”¨é‡
   - åˆ©ç”¨å¯èƒ½ãªç©ºãå®¹é‡
   - ãƒ¢ãƒ‡ãƒ«ã”ã¨ã®è©³ç´°

### ãƒ¢ãƒ‡ãƒ«ã®ä¿å­˜å ´æ‰€

ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: `./models/`

ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºã™ã‚‹å ´åˆã¯ `config.json` ã‚’ç·¨é›†:
```json
{
  "model_cache_dir": "./models/",
  "max_cache_size_gb": 100
}
```

ã¾ãŸã¯ç’°å¢ƒå¤‰æ•°ã§è¨­å®š:
```bash
export COLOR_CHART_MODEL_DIR=/path/to/models
```

## ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚º

### æ–°ã—ã„ãƒ¢ãƒ‡ãƒ«ã®è¿½åŠ 

`model_manager.py`ã®`AVAILABLE_MODELS`ã«è¿½åŠ :
```python
AVAILABLE_MODELS = {
    "Qwen3-VL-4B-Instruct": {
        "repo_id": "Qwen/Qwen3-VL-4B-Instruct",
        "size_gb": 8,
        "vram_gb": 10,
        "description": "è»½é‡ãƒ»é«˜é€Ÿãƒ¢ãƒ‡ãƒ«"
    },
    "Qwen3-VL-8B-Instruct": {
        "repo_id": "Qwen/Qwen3-VL-8B-Instruct",
        "size_gb": 16,
        "vram_gb": 16,
        "description": "é«˜ç²¾åº¦ãƒ¢ãƒ‡ãƒ«ï¼ˆæ¨å¥¨ï¼‰"
    },
    # ã‚«ã‚¹ã‚¿ãƒ ãƒ¢ãƒ‡ãƒ«ã‚’è¿½åŠ 
    "Custom-Model": {
        "repo_id": "username/custom-model",
        "size_gb": 12,
        "vram_gb": 14,
        "description": "ã‚«ã‚¹ã‚¿ãƒ ãƒ¢ãƒ‡ãƒ«"
    }
}
```

### ãƒ¢ãƒ‡ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã®ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚º
```python
from model_manager import ModelManager

manager = ModelManager(cache_dir="./my_models")

# ãƒ¢ãƒ‡ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆãƒ—ãƒ­ã‚°ãƒ©ãƒ çš„ã«ï¼‰
manager.download_model(
    "Qwen/Qwen3-VL-8B-Instruct",
    progress_callback=lambda p: print(f"Progress: {p}%")
)

# ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®ç¢ºèª
models = manager.list_downloaded_models()
for model in models:
    print(f"{model['name']}: {model['size_gb']:.2f} GB")
```

### é‡å­åŒ–ã«ã‚ˆã‚‹è»½é‡åŒ–

ãƒ¢ãƒ‡ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æ™‚ã«é‡å­åŒ–ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’æŒ‡å®šå¯èƒ½ï¼ˆå°†æ¥å®Ÿè£…äºˆå®šï¼‰:
```python
# 4-bité‡å­åŒ–ã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆVRAMä½¿ç”¨é‡ã‚’50%å‰Šæ¸›ï¼‰
manager.download_model(
    "Qwen/Qwen3-VL-8B-Instruct",
    quantization="4bit"
)
```

## ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

### ãƒ¢ãƒ‡ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãŒå¤±æ•—ã™ã‚‹

1. **ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ¥ç¶šã‚’ç¢ºèª**
```bash
ping huggingface.co
```

2. **Hugging Face ãƒˆãƒ¼ã‚¯ãƒ³ã®è¨­å®š**ï¼ˆãƒ—ãƒ©ã‚¤ãƒ™ãƒ¼ãƒˆãƒ¢ãƒ‡ãƒ«ã®å ´åˆï¼‰
```bash
huggingface-cli login
```

ã¾ãŸã¯ç’°å¢ƒå¤‰æ•°:
```bash
export HF_TOKEN=your_token_here
```

3. **å†è©¦è¡Œ**: ãƒ¢ãƒ‡ãƒ«ç®¡ç†ãƒšãƒ¼ã‚¸ã®ã€Œå†ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã€ãƒœã‚¿ãƒ³

### ãƒ‡ã‚£ã‚¹ã‚¯å®¹é‡ä¸è¶³

1. **ä¸è¦ãªãƒ¢ãƒ‡ãƒ«ã‚’å‰Šé™¤**: ãƒ¢ãƒ‡ãƒ«ç®¡ç†ãƒšãƒ¼ã‚¸ã‹ã‚‰å‰Šé™¤
2. **ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—**:
```bash
python -c "from model_manager import ModelManager; ModelManager().clean_cache()"
```

### ãƒ¢ãƒ‡ãƒ«ãŒèª­ã¿è¾¼ã‚ãªã„

1. **æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯**:
```python
from model_manager import ModelManager
manager = ModelManager()
manager.verify_model("Qwen3-VL-8B-Instruct")
```

2. **ãƒ¢ãƒ‡ãƒ«ã®å†ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰**: ç ´æã—ã¦ã„ã‚‹å ´åˆã¯å‰Šé™¤ã—ã¦å†ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰

### PyTorchã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã‚¨ãƒ©ãƒ¼
```bash
# CUDAç‰ˆï¼ˆGPUä½¿ç”¨ï¼‰
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu121

# CPUç‰ˆï¼ˆGPUãªã—ï¼‰
pip install torch torchvision --index-url https://download.pytorch.org/whl/cpu
```

### CUDAãŒèªè­˜ã•ã‚Œãªã„
```python
import torch
print(torch.cuda.is_available())  # Trueã«ãªã‚‹ã‹ç¢ºèª
print(torch.cuda.get_device_name(0))  # GPUåã‚’ç¢ºèª
```

### ãƒ¡ãƒ¢ãƒªä¸è¶³ã‚¨ãƒ©ãƒ¼ï¼ˆCUDA Out of Memoryï¼‰
1. **4Bãƒ¢ãƒ‡ãƒ«ã«åˆ‡ã‚Šæ›¿ãˆ**
2. **é‡å­åŒ–ã‚’ä½¿ç”¨**ï¼ˆå°†æ¥å®Ÿè£…ï¼‰
3. **ãƒãƒƒãƒã‚µã‚¤ã‚ºã‚’å‰Šæ¸›**

### Transformersã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚¨ãƒ©ãƒ¼
```bash
pip install transformers>=4.37.0 --upgrade
```

## ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–

### GPUä½¿ç”¨æ™‚ï¼ˆæ¨å¥¨è¨­å®šï¼‰
```python
model = Qwen2VLForConditionalGeneration.from_pretrained(
    model_path,
    torch_dtype=torch.bfloat16,
    device_map="auto",
    attn_implementation="flash_attention_2"
)
```

### ãƒ¡ãƒ¢ãƒªåŠ¹ç‡é‡è¦–
```python
from transformers import BitsAndBytesConfig

model = Qwen2VLForConditionalGeneration.from_pretrained(
    model_path,
    quantization_config=BitsAndBytesConfig(load_in_4bit=True),
    device_map="auto"
)
```

## é–‹ç™ºãƒ­ãƒ¼ãƒ‰ãƒãƒƒãƒ—

### Phase 1: ã‚³ã‚¢æ©Ÿèƒ½ï¼ˆv1.0ï¼‰
- [x] ã‚«ãƒ©ãƒ¼åˆ†ææ©Ÿèƒ½
- [x] ã‚³ãƒ³ãƒã‚¸ã‚·ãƒ§ãƒ³åˆ†ææ©Ÿèƒ½
- [x] ã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤è¡¨ç¤º
- [x] ãƒ¢ãƒ‡ãƒ«ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ 

### Phase 2: æ‹¡å¼µæ©Ÿèƒ½ï¼ˆv1.1ï¼‰
- [ ] ãƒãƒƒãƒå‡¦ç†æ©Ÿèƒ½ï¼ˆè¤‡æ•°ç”»åƒã®ä¸€æ‹¬åˆ†æï¼‰
- [ ] åˆ†æçµæœã®ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆï¼ˆJSON/CSV/PDFï¼‰
- [ ] ã‚«ã‚¹ã‚¿ãƒ ã‚«ãƒ©ãƒ¼ãƒ‘ãƒ¬ãƒƒãƒˆç”Ÿæˆ
- [ ] ç”»åƒæ¯”è¼ƒãƒ¢ãƒ¼ãƒ‰ï¼ˆ2æšã®ç”»åƒã‚’ä¸¦ã¹ã¦åˆ†æï¼‰

### Phase 3: ãƒ‡ãƒ¼ã‚¿ç®¡ç†ï¼ˆv1.2ï¼‰
- [ ] åˆ†æå±¥æ­´ã®ä¿å­˜ãƒ»æ¤œç´¢æ©Ÿèƒ½ï¼ˆSQLiteï¼‰
- [ ] ã‚¿ã‚°æ©Ÿèƒ½ï¼ˆClip Managerã‚¹ã‚¿ã‚¤ãƒ«ï¼‰
- [ ] åˆ†æçµæœã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°

### Phase 4: çµ±åˆæ©Ÿèƒ½ï¼ˆv2.0ï¼‰
- [ ] RESTful APIå¯¾å¿œ
- [ ] Stable Diffusionãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆçµ±åˆ
- [ ] Houdinié€£æºï¼ˆHDAã¨ã—ã¦ã®ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆï¼‰
- [ ] CLIç‰ˆã®å®Ÿè£…

### Phase 5: ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆï¼ˆv2.1ï¼‰
- [ ] Dockerå¯¾å¿œ
- [ ] Web APIç‰ˆ
- [ ] ãƒ¢ãƒã‚¤ãƒ«ã‚¢ãƒ—ãƒªå¯¾å¿œ

## APIä½¿ç”¨ä¾‹

### ãƒ¢ãƒ‡ãƒ«ç®¡ç†API
```python
from model_manager import ModelManager

# ãƒ¢ãƒ‡ãƒ«ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼åˆæœŸåŒ–
manager = ModelManager(cache_dir="./models")

# åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ã‚’å–å¾—
available = manager.get_available_models()
for model in available:
    print(f"{model['name']}: {model['size_gb']} GB")

# ãƒ¢ãƒ‡ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
def on_progress(percent, speed_mbps, eta_seconds):
    print(f"é€²æ—: {percent}% | é€Ÿåº¦: {speed_mbps:.1f} MB/s | æ®‹ã‚Š: {eta_seconds}ç§’")

manager.download_model(
    "Qwen/Qwen3-VL-8B-Instruct",
    progress_callback=on_progress
)

# ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’å–å¾—
downloaded = manager.list_downloaded_models()
for model in downloaded:
    print(f"{model['name']}: {model['size_gb']:.2f} GB ({model['last_used']})")

# ãƒ¢ãƒ‡ãƒ«å‰Šé™¤
manager.delete_model("Qwen/Qwen3-VL-4B-Instruct")

# ã‚­ãƒ£ãƒƒã‚·ãƒ¥æƒ…å ±
cache_info = manager.get_cache_info()
print(f"ä½¿ç”¨é‡: {cache_info['used_gb']:.2f} GB / {cache_info['total_gb']:.2f} GB")
```

### ã‚«ãƒ©ãƒ¼åˆ†æAPI
```python
from color_chart import ColorChartAnalyzer
from PIL import Image

# åˆæœŸåŒ–ï¼ˆãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’æŒ‡å®šï¼‰
analyzer = ColorChartAnalyzer(model_path="./models/Qwen3-VL-8B-Instruct")

# ç”»åƒèª­ã¿è¾¼ã¿
image = Image.open("artwork.jpg")

# ã‚«ãƒ©ãƒ¼åˆ†æ
colors, percentages = analyzer.extract_colors(image)
scheme, emoji = analyzer.classify_scheme(colors)
warm_pct, cool_pct = analyzer.get_color_temperature(colors, percentages)

print(f"ã‚«ãƒ©ãƒ¼ã‚¹ã‚­ãƒ¼ãƒ : {scheme} {emoji}")
print(f"è‰²æ¸©åº¦: æš–è‰²{warm_pct:.0f}% / å¯’è‰²{cool_pct:.0f}%")

# ã‚³ãƒ³ãƒã‚¸ã‚·ãƒ§ãƒ³åˆ†æ
composition_data = analyzer.analyze_composition("artwork.jpg")
print(f"ãƒ•ã‚©ãƒ¼ã‚«ãƒ«ãƒã‚¤ãƒ³ãƒˆ: {composition_data['focal_point']}")
```

## ç’°å¢ƒå¤‰æ•°
```bash
# ãƒ¢ãƒ‡ãƒ«ä¿å­˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
export COLOR_CHART_MODEL_DIR=/path/to/models

# Hugging Face ãƒˆãƒ¼ã‚¯ãƒ³ï¼ˆãƒ—ãƒ©ã‚¤ãƒ™ãƒ¼ãƒˆãƒ¢ãƒ‡ãƒ«ç”¨ï¼‰
export HF_TOKEN=your_token_here

# Hugging Face ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
export HF_HOME=/path/to/cache

# ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«
export TRANSFORMERS_VERBOSITY=error  # warning, info, debug

# æœ€å¤§ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚µã‚¤ã‚ºï¼ˆGBï¼‰
export COLOR_CHART_MAX_CACHE_GB=100
```

## ã‚·ã‚¹ãƒ†ãƒ è¦ä»¶

### æœ€å°è¦ä»¶
- CPU: 4ã‚³ã‚¢ä»¥ä¸Š
- RAM: 16GBä»¥ä¸Š
- GPU: NVIDIA GPU (CUDAå¯¾å¿œ) VRAM 8GBä»¥ä¸Š
- ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸: 30GBä»¥ä¸Šï¼ˆãƒ¢ãƒ‡ãƒ«ä¿å­˜ç”¨ï¼‰

### æ¨å¥¨è¦ä»¶
- CPU: 8ã‚³ã‚¢ä»¥ä¸Š
- RAM: 32GBä»¥ä¸Š
- GPU: NVIDIA RTX 3090/4090, A100, VRAM 16GBä»¥ä¸Š
- ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸: SSD 50GBä»¥ä¸Š

## ãƒ©ã‚¤ã‚»ãƒ³ã‚¹

MIT License

## ä½œæˆè€…

Ken - Technical Artist specializing in Houdini and procedural workflows

## å‚è€ƒè³‡æ–™

- [Qwen3-VL Model Card](https://huggingface.co/Qwen/Qwen3-VL-8B-Instruct)
- [Qwen3-VL GitHub](https://github.com/QwenLM/Qwen2-VL)
- [Transformers Documentation](https://huggingface.co/docs/transformers/)
- [Gradio Documentation](https://www.gradio.app/docs)
- Color Theory: Josef Albers "Interaction of Color"

## è¬è¾

ã“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¯ä»¥ä¸‹ã®ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’ä½¿ç”¨ã—ã¦ã„ã¾ã™:
- Qwen3-VL by Alibaba Cloud
- Transformers by Hugging Face
- Gradio by Hugging Face
- PyTorch by Meta AI