"""Color Chart - ç¾è¡“ç†è«–ã«åŸºã¥ã„ãŸç”»åƒåˆ†æãƒ„ãƒ¼ãƒ«

ãƒ­ãƒ¼ã‚«ãƒ«Vision LLMï¼ˆQwen3-VLï¼‰ã‚’ä½¿ç”¨ã—ã¦ã€ç”»åƒã®ã‚«ãƒ©ãƒ¼ã‚¹ã‚­ãƒ¼ãƒ ã€
ã‚³ãƒ³ãƒã‚¸ã‚·ãƒ§ãƒ³ã€å½©åº¦åˆ†å¸ƒãªã©ã‚’å°‚é–€çš„ã«åˆ†æã—ã¾ã™ã€‚
"""

import colorsys
import json
import re
import threading
from typing import Optional

import cv2
import gradio as gr
import numpy as np
import torch
from PIL import Image, ImageDraw, ImageFont
from sklearn.cluster import KMeans

from model_manager import AVAILABLE_MODELS, ModelManager

# ---------------------------------------------------------------------------
# ã‚«ãƒ©ãƒ¼åˆ†æ
# ---------------------------------------------------------------------------


class ColorAnalyzer:
    """K-meansã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã«ã‚ˆã‚‹ã‚«ãƒ©ãƒ¼åˆ†æ"""

    @staticmethod
    def extract_colors(
        image: Image.Image, n_colors: int = 6
    ) -> tuple[list[tuple[int, int, int]], list[float]]:
        """ç”»åƒã‹ã‚‰æ”¯é…çš„ãªè‰²ã‚’æŠ½å‡ºã™ã‚‹

        Returns:
            (colors, percentages): RGBã‚¿ãƒ—ãƒ«ã®ãƒªã‚¹ãƒˆã¨å„è‰²ã®å‰²åˆãƒªã‚¹ãƒˆ
        """
        img = image.copy().convert("RGB")
        # è¨ˆç®—é‡ã‚’æŠ‘ãˆã‚‹ãŸã‚ãƒªã‚µã‚¤ã‚º
        img.thumbnail((200, 200))
        pixels = np.array(img).reshape(-1, 3).astype(np.float64)

        kmeans = KMeans(n_clusters=n_colors, n_init=10, random_state=42)
        labels = kmeans.fit_predict(pixels)

        centers = kmeans.cluster_centers_.astype(int)
        counts = np.bincount(labels, minlength=n_colors)
        percentages = counts / counts.sum()

        # å‰²åˆã®å¤§ãã„é †ã«ã‚½ãƒ¼ãƒˆ
        order = np.argsort(-percentages)
        colors = [tuple(centers[i]) for i in order]
        percentages = [float(percentages[i]) for i in order]

        return colors, percentages

    @staticmethod
    def rgb_to_hex(r: int, g: int, b: int) -> str:
        return f"#{r:02X}{g:02X}{b:02X}"

    @staticmethod
    def rgb_to_hsv(r: int, g: int, b: int) -> tuple[float, float, float]:
        """RGBâ†’HSV (H: 0-360, S: 0-1, V: 0-1)"""
        h, s, v = colorsys.rgb_to_hsv(r / 255, g / 255, b / 255)
        return h * 360, s, v

    @staticmethod
    def classify_scheme(
        colors: list[tuple[int, int, int]],
    ) -> tuple[str, str]:
        """ã‚«ãƒ©ãƒ¼ã‚¹ã‚­ãƒ¼ãƒ ã‚’åˆ†é¡ã™ã‚‹

        Returns:
            (scheme_name, emoji)
        """
        if len(colors) < 2:
            return "Monochromatic", "ğŸ¨"

        hues = [ColorAnalyzer.rgb_to_hsv(*c)[0] for c in colors]
        sats = [ColorAnalyzer.rgb_to_hsv(*c)[1] for c in colors]

        # å½©åº¦ãŒä½ã„è‰²ã¯ã‚¹ã‚­ãƒ¼ãƒ ã®åˆ¤å®šã«ä½¿ã‚ãªã„
        chromatic = [(h, s) for h, s in zip(hues, sats) if s > 0.15]
        if len(chromatic) < 2:
            return "Monochromatic", "ğŸ¨"

        chroma_hues = [h for h, _ in chromatic]

        # è‰²ç›¸ã®æœ€å¤§å·®åˆ†ã‚’ç®—å‡º
        def hue_diff(h1: float, h2: float) -> float:
            d = abs(h1 - h2)
            return min(d, 360 - d)

        diffs = []
        for i in range(len(chroma_hues)):
            for j in range(i + 1, len(chroma_hues)):
                diffs.append(hue_diff(chroma_hues[i], chroma_hues[j]))

        max_diff = max(diffs)
        avg_diff = sum(diffs) / len(diffs)

        # è‰²ç›¸ã®ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ãŒç‹­ã„ â†’ Analogous
        if max_diff < 60:
            return "Analogous", "ğŸŒˆ"

        # è£œè‰²ã«è¿‘ã„å¯¾ï¼ˆ150-180åº¦ï¼‰
        has_complement = any(150 <= d <= 180 for d in diffs)
        # 120åº¦ä»˜è¿‘ã®å¯¾
        has_triad = any(100 <= d <= 140 for d in diffs)

        if has_complement:
            # åˆ†è£‚è£œè‰²: è£œè‰²ãƒšã‚¢ + ä¸­é–“è‰²
            split = any(30 <= d <= 90 for d in diffs)
            if split:
                return "Split-Complementary", "ğŸ”€"
            return "Complementary", "ğŸ”´ğŸ”µ"

        if has_triad:
            return "Triadic", "ğŸ”º"

        if max_diff < 90:
            return "Analogous", "ğŸŒˆ"

        return "Complementary", "ğŸ”´ğŸ”µ"

    @staticmethod
    def get_color_temperature(
        colors: list[tuple[int, int, int]], percentages: list[float]
    ) -> tuple[float, float]:
        """æš–è‰²/å¯’è‰²ã®æ¯”ç‡ã‚’è¿”ã™ (warm_pct, cool_pct)"""
        warm = 0.0
        cool = 0.0
        for (r, g, b), pct in zip(colors, percentages):
            h, s, _ = ColorAnalyzer.rgb_to_hsv(r, g, b)
            if s < 0.1:
                # ç„¡å½©è‰²ã¯ä¸­ç«‹æ‰±ã„
                warm += pct * 0.5
                cool += pct * 0.5
            elif h <= 60 or h >= 300:
                # æš–è‰²ï¼ˆèµ¤ã€œé»„ã€ãƒã‚¼ãƒ³ã‚¿å¯„ã‚Šï¼‰
                warm += pct
            elif 60 < h < 180:
                # ä¸­é–“ã€œå¯’è‰²ã¸ã®ã‚°ãƒ©ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³
                ratio = (h - 60) / 120  # 0â†’1
                warm += pct * (1 - ratio)
                cool += pct * ratio
            else:
                # 180-300: å¯’è‰²
                cool += pct

        total = warm + cool
        if total == 0:
            return 50.0, 50.0
        return round(warm / total * 100, 1), round(cool / total * 100, 1)


# ---------------------------------------------------------------------------
# ã‚³ãƒ³ãƒã‚¸ã‚·ãƒ§ãƒ³åˆ†æï¼ˆVision LLMï¼‰
# ---------------------------------------------------------------------------


COMPOSITION_PROMPT = """\
ã‚ãªãŸã¯ç¾è¡“ã®å°‚é–€å®¶ã§ã™ã€‚ã“ã®ç”»åƒã®ã‚³ãƒ³ãƒã‚¸ã‚·ãƒ§ãƒ³ï¼ˆæ§‹å›³ï¼‰ã‚’åˆ†æã—ã¦ãã ã•ã„ã€‚
ä»¥ä¸‹ã®JSONå½¢å¼ã§å›ç­”ã—ã¦ãã ã•ã„ã€‚JSONã®ã¿å‡ºåŠ›ã—ã€ä»–ã®ãƒ†ã‚­ã‚¹ãƒˆã¯å«ã‚ãªã„ã§ãã ã•ã„ã€‚

{
  "focal_points": [
    {"x": 0.0-1.0ã®ç›¸å¯¾åº§æ¨™, "y": 0.0-1.0ã®ç›¸å¯¾åº§æ¨™, "description": "èª¬æ˜"}
  ],
  "composition_type": "ä¸‰åˆ†å‰²æ³• / é»„é‡‘æ¯” / ä¸­å¤®é…ç½® / å¯¾è§’ç·š / Så­— / Lå­— / ãã®ä»–",
  "balance": "å¯¾ç§° / éå¯¾ç§° / ãƒ©ã‚¸ã‚¢ãƒ«",
  "negative_space": "å¤šã„ / é©åº¦ / å°‘ãªã„",
  "eye_flow": "è¦–ç·šã®æµã‚Œã®èª¬æ˜",
  "strengths": ["å¼·ã¿ã®ãƒªã‚¹ãƒˆ"],
  "improvements": ["æ”¹å–„ææ¡ˆã®ãƒªã‚¹ãƒˆ"]
}
"""


class CompositionAnalyzer:
    """Vision LLMã‚’ä½¿ã£ãŸã‚³ãƒ³ãƒã‚¸ã‚·ãƒ§ãƒ³åˆ†æ"""

    def __init__(self):
        self.model = None
        self.processor = None
        self.model_name = None

    def load_model(self, model_path: str):
        """Qwen3-VLãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã‚€"""
        from transformers import AutoProcessor, Qwen2VLForConditionalGeneration

        if self.model_name == model_path:
            return  # æ—¢ã«ãƒ­ãƒ¼ãƒ‰æ¸ˆã¿

        # æ—¢å­˜ãƒ¢ãƒ‡ãƒ«ã®ãƒ¡ãƒ¢ãƒªè§£æ”¾
        if self.model is not None:
            del self.model
            del self.processor
            torch.cuda.empty_cache() if torch.cuda.is_available() else None

        device = "cuda" if torch.cuda.is_available() else "cpu"
        dtype = torch.bfloat16 if device == "cuda" else torch.float32

        self.processor = AutoProcessor.from_pretrained(model_path)
        self.model = Qwen2VLForConditionalGeneration.from_pretrained(
            model_path,
            torch_dtype=dtype,
            device_map="auto" if device == "cuda" else None,
        )
        if device == "cpu":
            self.model = self.model.to(device)

        self.model_name = model_path

    def analyze(self, image: Image.Image) -> dict:
        """ç”»åƒã®ã‚³ãƒ³ãƒã‚¸ã‚·ãƒ§ãƒ³ã‚’åˆ†æã™ã‚‹"""
        if self.model is None:
            raise RuntimeError("ãƒ¢ãƒ‡ãƒ«ãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã„ã¾ã›ã‚“ã€‚å…ˆã«load_model()ã‚’å‘¼ã‚“ã§ãã ã•ã„ã€‚")

        from qwen_vl_utils import process_vision_info

        messages = [
            {
                "role": "user",
                "content": [
                    {"type": "image", "image": image},
                    {"type": "text", "text": COMPOSITION_PROMPT},
                ],
            }
        ]

        text = self.processor.apply_chat_template(
            messages, tokenize=False, add_generation_prompt=True
        )
        image_inputs, video_inputs = process_vision_info(messages)
        inputs = self.processor(
            text=[text],
            images=image_inputs,
            videos=video_inputs,
            padding=True,
            return_tensors="pt",
        ).to(self.model.device)

        with torch.no_grad():
            output_ids = self.model.generate(**inputs, max_new_tokens=1024)

        # å…¥åŠ›éƒ¨åˆ†ã‚’é™¤ã„ãŸå‡ºåŠ›ã®ã¿ãƒ‡ã‚³ãƒ¼ãƒ‰
        generated = output_ids[:, inputs.input_ids.shape[1]:]
        response = self.processor.batch_decode(
            generated, skip_special_tokens=True
        )[0]

        return self._parse_response(response)

    @staticmethod
    def _parse_response(response: str) -> dict:
        """LLMã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‹ã‚‰JSONã‚’æŠ½å‡ºã—ã¦ãƒ‘ãƒ¼ã‚¹ã™ã‚‹"""
        # JSONãƒ–ãƒ­ãƒƒã‚¯ã‚’æ¢ã™
        json_match = re.search(r"\{[\s\S]*\}", response)
        if json_match:
            try:
                return json.loads(json_match.group())
            except json.JSONDecodeError:
                pass

        return {
            "focal_points": [],
            "composition_type": "è§£æä¸èƒ½",
            "balance": "ä¸æ˜",
            "negative_space": "ä¸æ˜",
            "eye_flow": response,
            "strengths": [],
            "improvements": [],
            "raw_response": response,
        }


# ---------------------------------------------------------------------------
# ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ©ã‚¤ã‚¼ãƒ¼ã‚·ãƒ§ãƒ³
# ---------------------------------------------------------------------------


class Visualizer:
    """ã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤ã¨ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ©ã‚¤ã‚¼ãƒ¼ã‚·ãƒ§ãƒ³ç”Ÿæˆ"""

    @staticmethod
    def draw_rule_of_thirds(image: Image.Image) -> Image.Image:
        """ä¸‰åˆ†å‰²æ³•ã‚°ãƒªãƒƒãƒ‰ã‚’æç”»"""
        overlay = image.copy()
        draw = ImageDraw.Draw(overlay)
        w, h = overlay.size

        line_color = (255, 255, 255, 180)
        line_width = 2

        for i in range(1, 3):
            x = w * i // 3
            draw.line([(x, 0), (x, h)], fill=line_color, width=line_width)
        for i in range(1, 3):
            y = h * i // 3
            draw.line([(0, y), (w, y)], fill=line_color, width=line_width)

        return overlay

    @staticmethod
    def draw_focal_points(
        image: Image.Image,
        focal_points: list[dict],
    ) -> Image.Image:
        """ãƒ•ã‚©ãƒ¼ã‚«ãƒ«ãƒã‚¤ãƒ³ãƒˆã‚’æç”»"""
        overlay = image.copy()
        draw = ImageDraw.Draw(overlay)
        w, h = overlay.size

        for i, fp in enumerate(focal_points):
            x = fp.get("x", 0.5) * w
            y = fp.get("y", 0.5) * h
            radius = min(w, h) * 0.03
            color = (255, 50, 50)

            # å††
            draw.ellipse(
                [x - radius, y - radius, x + radius, y + radius],
                outline=color,
                width=3,
            )
            # åå­—
            cross = radius * 1.5
            draw.line([(x - cross, y), (x + cross, y)], fill=color, width=2)
            draw.line([(x, y - cross), (x, y + cross)], fill=color, width=2)

            # ãƒ©ãƒ™ãƒ«
            label = fp.get("description", f"Point {i + 1}")
            try:
                font = ImageFont.truetype("arial.ttf", max(12, min(w, h) // 40))
            except OSError:
                font = ImageFont.load_default()
            draw.text(
                (x + radius + 5, y - radius),
                label,
                fill=color,
                font=font,
            )

        return overlay

    @staticmethod
    def create_saturation_heatmap(image: Image.Image) -> Image.Image:
        """å½©åº¦ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã‚’ç”Ÿæˆ"""
        img_np = np.array(image.convert("RGB"))
        hsv = cv2.cvtColor(img_np, cv2.COLOR_RGB2HSV)
        saturation = hsv[:, :, 1]

        # ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ï¼ˆCOLORMAP_JETï¼‰
        heatmap = cv2.applyColorMap(saturation, cv2.COLORMAP_JET)
        heatmap_rgb = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB)

        # å…ƒç”»åƒã¨ãƒ–ãƒ¬ãƒ³ãƒ‰
        blended = cv2.addWeighted(img_np, 0.4, heatmap_rgb, 0.6, 0)
        return Image.fromarray(blended)

    @staticmethod
    def create_color_swatch(
        colors: list[tuple[int, int, int]],
        percentages: list[float],
    ) -> Image.Image:
        """ã‚«ãƒ©ãƒ¼ã‚¹ã‚¦ã‚©ãƒƒãƒç”»åƒã‚’ç”Ÿæˆ"""
        swatch_w, swatch_h = 600, 120
        swatch = Image.new("RGB", (swatch_w, swatch_h), (30, 30, 30))
        draw = ImageDraw.Draw(swatch)

        try:
            font = ImageFont.truetype("arial.ttf", 13)
        except OSError:
            font = ImageFont.load_default()

        x = 0
        for color, pct in zip(colors, percentages):
            w = max(int(swatch_w * pct), 1)
            draw.rectangle([x, 0, x + w, swatch_h - 30], fill=color)

            hex_str = ColorAnalyzer.rgb_to_hex(*color)
            pct_str = f"{pct * 100:.1f}%"
            text_x = x + 4
            text_y = swatch_h - 26
            # ãƒ†ã‚­ã‚¹ãƒˆã®è¼åº¦ã«å¿œã˜ã¦ç™½ã‹é»’
            brightness = (color[0] * 299 + color[1] * 587 + color[2] * 114) / 1000
            text_color = (255, 255, 255) if brightness < 128 else (0, 0, 0)
            draw.text((text_x, text_y), f"{hex_str} {pct_str}", fill=text_color, font=font)

            x += w

        return swatch


# ---------------------------------------------------------------------------
# Gradio UI
# ---------------------------------------------------------------------------

# ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
model_manager = ModelManager()
composition_analyzer = CompositionAnalyzer()


def get_model_choices() -> list[str]:
    """ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®ãƒªã‚¹ãƒˆã‚’è¿”ã™"""
    return [m["name"] for m in model_manager.list_downloaded_models()] or []


def run_analysis(
    image: Optional[Image.Image],
    model_name: str,
    do_color: bool,
    do_composition: bool,
) -> tuple:
    """åˆ†æã‚’å®Ÿè¡Œã™ã‚‹ï¼ˆGradioã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰

    Returns:
        (color_swatch, color_text, composition_text, overlay_image, composition_data_json)
    """
    if image is None:
        return None, "ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚", "", None, "{}"

    color_swatch = None
    color_text = ""
    composition_text = ""
    composition_data = {}
    overlay_image = image.copy()

    # --- ã‚«ãƒ©ãƒ¼åˆ†æ ---
    if do_color:
        colors, percentages = ColorAnalyzer.extract_colors(image)
        scheme, emoji = ColorAnalyzer.classify_scheme(colors)
        warm, cool = ColorAnalyzer.get_color_temperature(colors, percentages)
        color_swatch = Visualizer.create_color_swatch(colors, percentages)

        lines = [f"## ã‚«ãƒ©ãƒ¼ã‚¹ã‚­ãƒ¼ãƒ : {scheme} {emoji}\n"]
        lines.append(f"**è‰²æ¸©åº¦**: æš–è‰² {warm}% / å¯’è‰² {cool}%\n")
        lines.append("### æ”¯é…è‰²\n")
        lines.append("| # | HEX | RGB | å‰²åˆ |")
        lines.append("|---|-----|-----|------|")
        for i, (c, p) in enumerate(zip(colors, percentages), 1):
            hex_val = ColorAnalyzer.rgb_to_hex(*c)
            lines.append(f"| {i} | {hex_val} | ({c[0]}, {c[1]}, {c[2]}) | {p*100:.1f}% |")
        color_text = "\n".join(lines)

    # --- ã‚³ãƒ³ãƒã‚¸ã‚·ãƒ§ãƒ³åˆ†æ ---
    if do_composition:
        if not model_name:
            composition_text = "ãƒ¢ãƒ‡ãƒ«ãŒé¸æŠã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ãƒ¢ãƒ‡ãƒ«ç®¡ç†ã‚¿ãƒ–ã‹ã‚‰ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚"
        else:
            model_path = model_manager.get_model_path(model_name)
            if model_path is None:
                composition_text = f"ãƒ¢ãƒ‡ãƒ« '{model_name}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚"
            else:
                try:
                    composition_text = "ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿ä¸­..."
                    composition_analyzer.load_model(model_path)
                    composition_data = composition_analyzer.analyze(image)

                    lines = ["## ã‚³ãƒ³ãƒã‚¸ã‚·ãƒ§ãƒ³åˆ†æ\n"]
                    lines.append(f"**æ§‹å›³ã‚¿ã‚¤ãƒ—**: {composition_data.get('composition_type', 'ä¸æ˜')}")
                    lines.append(f"**ãƒãƒ©ãƒ³ã‚¹**: {composition_data.get('balance', 'ä¸æ˜')}")
                    lines.append(f"**ãƒã‚¬ãƒ†ã‚£ãƒ–ã‚¹ãƒšãƒ¼ã‚¹**: {composition_data.get('negative_space', 'ä¸æ˜')}")
                    lines.append(f"\n**è¦–ç·šã®æµã‚Œ**: {composition_data.get('eye_flow', 'ä¸æ˜')}\n")

                    fps = composition_data.get("focal_points", [])
                    if fps:
                        lines.append("### ãƒ•ã‚©ãƒ¼ã‚«ãƒ«ãƒã‚¤ãƒ³ãƒˆ\n")
                        for i, fp in enumerate(fps, 1):
                            desc = fp.get("description", "")
                            x = fp.get("x", 0)
                            y = fp.get("y", 0)
                            lines.append(f"{i}. ({x:.2f}, {y:.2f}) - {desc}")

                    strengths = composition_data.get("strengths", [])
                    if strengths:
                        lines.append("\n### å¼·ã¿\n")
                        for s in strengths:
                            lines.append(f"- {s}")

                    improvements = composition_data.get("improvements", [])
                    if improvements:
                        lines.append("\n### æ”¹å–„ææ¡ˆ\n")
                        for imp in improvements:
                            lines.append(f"- {imp}")

                    composition_text = "\n".join(lines)
                except Exception as e:
                    composition_text = f"ã‚³ãƒ³ãƒã‚¸ã‚·ãƒ§ãƒ³åˆ†æã‚¨ãƒ©ãƒ¼: {e}"

    return (
        color_swatch,
        color_text,
        composition_text,
        overlay_image,
        json.dumps(composition_data, ensure_ascii=False),
    )


def apply_overlay(
    image: Optional[Image.Image],
    composition_data_json: str,
    show_grid: bool,
    show_focal: bool,
    show_heatmap: bool,
) -> Optional[Image.Image]:
    """ã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤ã‚’é©ç”¨ã™ã‚‹"""
    if image is None:
        return None

    result = image.copy()

    if show_heatmap:
        result = Visualizer.create_saturation_heatmap(result)

    if show_grid:
        result = Visualizer.draw_rule_of_thirds(result)

    if show_focal and composition_data_json:
        try:
            data = json.loads(composition_data_json)
            fps = data.get("focal_points", [])
            if fps:
                result = Visualizer.draw_focal_points(result, fps)
        except (json.JSONDecodeError, TypeError):
            pass

    return result


# --- ãƒ¢ãƒ‡ãƒ«ç®¡ç†ã‚¿ãƒ–ã®ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ ---


def refresh_available_models():
    """åˆ©ç”¨å¯èƒ½ãƒ¢ãƒ‡ãƒ«ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’æ›´æ–°"""
    models = model_manager.get_available_models()
    rows = []
    for m in models:
        status = "âœ… ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æ¸ˆã¿" if m["downloaded"] else "â¬‡ï¸ æœªãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"
        rows.append([
            m["name"],
            f"{m['size_gb']} GB",
            f"{m['vram_gb']} GB",
            m["speed"],
            m["accuracy"],
            status,
        ])
    return rows


def refresh_downloaded_models():
    """ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’æ›´æ–°"""
    models = model_manager.list_downloaded_models()
    if not models:
        return [["ï¼ˆãªã—ï¼‰", "", ""]]
    rows = []
    for m in models:
        rows.append([m["name"], f"{m['size_gb']:.2f} GB", m["last_used"]])
    return rows


def get_storage_info() -> str:
    """ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸æƒ…å ±ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’è¿”ã™"""
    info = model_manager.get_cache_info()
    lines = [
        f"**ä½¿ç”¨é‡**: {info['used_gb']:.2f} GB",
        f"**ç©ºãå®¹é‡**: {info['free_gb']:.1f} GB",
        f"**åˆè¨ˆ**: {info['total_gb']:.1f} GB",
    ]
    if info["model_sizes"]:
        lines.append("\n**ãƒ¢ãƒ‡ãƒ«åˆ¥ä½¿ç”¨é‡**:")
        for name, size in info["model_sizes"].items():
            lines.append(f"- {name}: {size:.2f} GB")
    return "\n".join(lines)


def download_model_ui(model_name: str, progress=gr.Progress()):
    """ãƒ¢ãƒ‡ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆUIã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰"""
    if not model_name:
        return "ãƒ¢ãƒ‡ãƒ«åã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚", refresh_available_models(), refresh_downloaded_models(), get_storage_info(), gr.update(choices=get_model_choices())

    if model_manager.is_downloaded(model_name):
        return f"{model_name} ã¯æ—¢ã«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æ¸ˆã¿ã§ã™ã€‚", refresh_available_models(), refresh_downloaded_models(), get_storage_info(), gr.update(choices=get_model_choices())

    progress(0, desc=f"{model_name} ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­...")
    try:
        model_manager.download_model(model_name)
        progress(1.0, desc="å®Œäº†")
        return (
            f"âœ… {model_name} ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãŒå®Œäº†ã—ã¾ã—ãŸã€‚",
            refresh_available_models(),
            refresh_downloaded_models(),
            get_storage_info(),
            gr.update(choices=get_model_choices()),
        )
    except Exception as e:
        return (
            f"âŒ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {e}",
            refresh_available_models(),
            refresh_downloaded_models(),
            get_storage_info(),
            gr.update(choices=get_model_choices()),
        )


def delete_model_ui(model_name: str):
    """ãƒ¢ãƒ‡ãƒ«å‰Šé™¤ï¼ˆUIã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰"""
    if not model_name:
        return "ãƒ¢ãƒ‡ãƒ«åã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚", refresh_available_models(), refresh_downloaded_models(), get_storage_info(), gr.update(choices=get_model_choices())

    if model_manager.delete_model(model_name):
        return (
            f"âœ… {model_name} ã‚’å‰Šé™¤ã—ã¾ã—ãŸã€‚",
            refresh_available_models(),
            refresh_downloaded_models(),
            get_storage_info(),
            gr.update(choices=get_model_choices()),
        )
    return (
        f"âŒ {model_name} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚",
        refresh_available_models(),
        refresh_downloaded_models(),
        get_storage_info(),
        gr.update(choices=get_model_choices()),
    )


# ---------------------------------------------------------------------------
# ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³æ§‹ç¯‰
# ---------------------------------------------------------------------------


def create_app() -> gr.Blocks:
    """Gradio UIã‚’æ§‹ç¯‰ã—ã¦è¿”ã™"""

    has_models = len(get_model_choices()) > 0

    initial_tab = "analysis" if has_models else "model_management"

    with gr.Blocks(
        title="Color Chart - ç”»åƒåˆ†æãƒ„ãƒ¼ãƒ«",
    ) as app:
        gr.Markdown("# ğŸ¨ Color Chart\nç¾è¡“ç†è«–ã«åŸºã¥ã„ãŸç”»åƒåˆ†æãƒ„ãƒ¼ãƒ«")

        # åˆ†æçµæœã®å†…éƒ¨çŠ¶æ…‹
        composition_data_state = gr.State("{}")

        with gr.Tabs(selected=initial_tab) as tabs:
            # ===== åˆ†æã‚¿ãƒ– =====
            with gr.Tab("ğŸ¨ åˆ†æ", id="analysis"):
                with gr.Row():
                    # --- å·¦ã‚«ãƒ©ãƒ : å…¥åŠ› ---
                    with gr.Column(scale=1):
                        input_image = gr.Image(
                            label="ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰",
                            type="pil",
                            height=400,
                        )
                        model_dropdown = gr.Dropdown(
                            label="ãƒ¢ãƒ‡ãƒ«é¸æŠ",
                            choices=get_model_choices(),
                            value=get_model_choices()[0] if has_models else None,
                            interactive=True,
                        )
                        with gr.Row():
                            do_color = gr.Checkbox(label="ã‚«ãƒ©ãƒ¼åˆ†æ", value=True)
                            do_composition = gr.Checkbox(label="ã‚³ãƒ³ãƒã‚¸ã‚·ãƒ§ãƒ³åˆ†æ", value=True)
                        analyze_btn = gr.Button("ğŸ” åˆ†æé–‹å§‹", variant="primary", size="lg")

                        gr.Markdown("### ã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤è¡¨ç¤º")
                        with gr.Row():
                            show_grid = gr.Checkbox(label="ä¸‰åˆ†å‰²æ³•", value=False)
                            show_focal = gr.Checkbox(label="ãƒ•ã‚©ãƒ¼ã‚«ãƒ«ãƒã‚¤ãƒ³ãƒˆ", value=False)
                            show_heatmap = gr.Checkbox(label="å½©åº¦ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—", value=False)

                    # --- å³ã‚«ãƒ©ãƒ : çµæœ ---
                    with gr.Column(scale=1):
                        color_swatch = gr.Image(label="ã‚«ãƒ©ãƒ¼ã‚¹ã‚¦ã‚©ãƒƒãƒ", height=140)
                        color_result = gr.Markdown(label="ã‚«ãƒ©ãƒ¼åˆ†æçµæœ")
                        composition_result = gr.Markdown(label="ã‚³ãƒ³ãƒã‚¸ã‚·ãƒ§ãƒ³åˆ†æçµæœ")
                        overlay_image = gr.Image(label="ã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤è¡¨ç¤º", height=400)

                # åˆ†æãƒœã‚¿ãƒ³ã®ã‚¤ãƒ™ãƒ³ãƒˆ
                analyze_btn.click(
                    fn=run_analysis,
                    inputs=[input_image, model_dropdown, do_color, do_composition],
                    outputs=[
                        color_swatch,
                        color_result,
                        composition_result,
                        overlay_image,
                        composition_data_state,
                    ],
                )

                # ã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤ã®ãƒã‚§ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹å¤‰æ›´æ™‚
                overlay_inputs = [
                    input_image,
                    composition_data_state,
                    show_grid,
                    show_focal,
                    show_heatmap,
                ]
                for checkbox in [show_grid, show_focal, show_heatmap]:
                    checkbox.change(
                        fn=apply_overlay,
                        inputs=overlay_inputs,
                        outputs=[overlay_image],
                    )

            # ===== ãƒ¢ãƒ‡ãƒ«ç®¡ç†ã‚¿ãƒ– =====
            with gr.Tab("ğŸ”§ ãƒ¢ãƒ‡ãƒ«ç®¡ç†", id="model_management"):
                gr.Markdown("## ãƒ¢ãƒ‡ãƒ«ç®¡ç†")

                with gr.Row():
                    with gr.Column():
                        gr.Markdown("### ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«")
                        available_table = gr.Dataframe(
                            headers=["ãƒ¢ãƒ‡ãƒ«å", "ã‚µã‚¤ã‚º", "VRAM", "é€Ÿåº¦", "ç²¾åº¦", "çŠ¶æ…‹"],
                            value=refresh_available_models(),
                            interactive=False,
                        )
                        with gr.Row():
                            download_model_name = gr.Dropdown(
                                label="ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ãƒ¢ãƒ‡ãƒ«",
                                choices=list(AVAILABLE_MODELS.keys()),
                            )
                            download_btn = gr.Button("â¬‡ï¸ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", variant="primary")
                        download_status = gr.Markdown("")

                    with gr.Column():
                        gr.Markdown("### ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«")
                        downloaded_table = gr.Dataframe(
                            headers=["ãƒ¢ãƒ‡ãƒ«å", "ã‚µã‚¤ã‚º", "æœ€çµ‚ä½¿ç”¨"],
                            value=refresh_downloaded_models(),
                            interactive=False,
                        )
                        with gr.Row():
                            delete_model_name = gr.Dropdown(
                                label="å‰Šé™¤ã™ã‚‹ãƒ¢ãƒ‡ãƒ«",
                                choices=get_model_choices(),
                            )
                            delete_btn = gr.Button("ğŸ—‘ï¸ å‰Šé™¤", variant="stop")
                        delete_status = gr.Markdown("")

                gr.Markdown("### ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸æƒ…å ±")
                storage_info = gr.Markdown(value=get_storage_info())

                # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³
                download_btn.click(
                    fn=download_model_ui,
                    inputs=[download_model_name],
                    outputs=[
                        download_status,
                        available_table,
                        downloaded_table,
                        storage_info,
                        model_dropdown,
                    ],
                )

                # å‰Šé™¤ãƒœã‚¿ãƒ³
                delete_btn.click(
                    fn=delete_model_ui,
                    inputs=[delete_model_name],
                    outputs=[
                        delete_status,
                        available_table,
                        downloaded_table,
                        storage_info,
                        model_dropdown,
                    ],
                )

    return app


if __name__ == "__main__":
    app = create_app()
    app.launch(server_name="0.0.0.0", server_port=7860, theme=gr.themes.Soft(), share=False)
